#!/usr/bin/env python3
"""
WeChat Chat Extractor

ç»™å®škey pathï¼Œéå†æ‰€æœ‰æ•°æ®åº“é‡Œçš„chatè¡¨ï¼Œè¾“å‡ºjsonæ–‡ä»¶

ç”¨æ³•:
    python wechat_chat_extractor.py /path/to/.keys

éœ€è¦å®‰è£…çš„ä¾èµ–:
    pip install pysqlcipher3
"""

import argparse
import csv
import json
import logging
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple

try:
    from pysqlcipher3 import dbapi2 as sqlite
except ImportError as e:
    print(f"ç¼ºå°‘å¿…è¦ä¾èµ–: {e}")
    print("è¯·å®‰è£…ä¾èµ–: pip install pysqlcipher3")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class WeChatChatExtractor:
    """WeChatèŠå¤©è®°å½•æå–å™¨"""
    
    def __init__(self, keys_file_path: str):
        """
        åˆå§‹åŒ–æå–å™¨
        
        Args:
            keys_file_path: .keysæ–‡ä»¶è·¯å¾„
        """
        self.keys_file_path = Path(keys_file_path)
        self.databases: List[Dict[str, Any]] = []
        self.chat_data: List[Dict[str, Any]] = []
        
    def extract_db_type(self, filepath: str) -> str:
        """ä»æ–‡ä»¶è·¯å¾„æå–æ•°æ®åº“ç±»å‹"""
        parts = filepath.split('/')
        for i in range(len(parts) - 2, -1, -1):
            if parts[i] != '':
                return parts[i]
        return 'unknown'
        
    def parse_keys(self, content: str) -> List[Dict[str, Any]]:
        """è§£æ.keysæ–‡ä»¶å†…å®¹"""
        keys = []
        lines = content.split('\n')
        
        current_path = ''
        current_key = ''
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # åŒ¹é…è·¯å¾„è¡Œ
            path_match = re.match(r"sqlcipher db path: '([^']+)'", line)
            if path_match:
                current_path = path_match.group(1)
                continue
            
            # åŒ¹é…å¯†é’¥è¡Œ
            key_match = re.match(r'PRAGMA key = "([^"]+)"', line)
            if key_match and current_path:
                current_key = key_match.group(1)
                
                keys.append({
                    'path': current_path,
                    'key': current_key,
                    'cipher_compatibility': 3,  # é»˜è®¤å…¼å®¹æ€§ç‰ˆæœ¬
                    'type': self.extract_db_type(current_path)
                })
                
                current_path = ''
                current_key = ''
        
        return keys
        
    def load_keys(self) -> None:
        """åŠ è½½.keysæ–‡ä»¶å¹¶è§£ææ•°æ®åº“ä¿¡æ¯"""
        try:
            with open(self.keys_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"åŠ è½½keysæ–‡ä»¶: {self.keys_file_path}")
            
            # è§£ækeysæ–‡ä»¶
            parsed_keys = self.parse_keys(content)
            
            for key_info in parsed_keys:
                db_path = key_info['path']
                
                # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(db_path):
                    db_size = os.path.getsize(db_path)
                    self.databases.append({
                        'type': key_info['type'],
                        'path': db_path,
                        'key': key_info['key'],
                        'cipher_compatibility': key_info['cipher_compatibility']
                    })
                    logger.info(f"ğŸ“ æ‰¾åˆ°æ•°æ®åº“: {key_info['type']} - {Path(db_path).name} ({db_size:,} bytes)")
                    logger.info(f"   è·¯å¾„: {db_path}")
                    logger.info(f"   å¯†é’¥: {key_info['key']}")
                    logger.info(f"   cipher_compatibility: {key_info['cipher_compatibility']}")
                else:
                    logger.warning(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            
            logger.info(f"æ€»å…±åŠ è½½äº† {len(self.databases)} ä¸ªæœ‰æ•ˆæ•°æ®åº“")
            
        except Exception as e:
            logger.error(f"åŠ è½½keysæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def connect_database(self, db_info: Dict[str, Any]) -> Optional[sqlite.Connection]:
        """
        è¿æ¥SQLCipheræ•°æ®åº“
        
        Args:
            db_info: æ•°æ®åº“ä¿¡æ¯å­—å…¸
            
        Returns:
            æ•°æ®åº“è¿æ¥å¯¹è±¡æˆ–None
        """
        db_name = Path(db_info['path']).name
        logger.debug(f"ğŸ” å°è¯•è¿æ¥æ•°æ®åº“: {db_name}")
        logger.debug(f"   è·¯å¾„: {db_info['path']}")
        logger.debug(f"   å¯†é’¥: {db_info['key']}")
        logger.debug(f"   cipher_compatibility: {db_info['cipher_compatibility']}")
        
        # å°è¯•ä¸åŒçš„è¿æ¥æ–¹å¼
        key_formats = []
        original_key = db_info['key']
        
        if original_key.startswith("x'") and original_key.endswith("'"):
            hex_key = original_key[2:-1]
            key_formats = [
                f"x'{hex_key}'",           # æ ‡å‡†åå…­è¿›åˆ¶æ ¼å¼
                original_key,             # åŸå§‹æ ¼å¼
                f'"{original_key}"',      # å¸¦å¼•å·çš„åŸå§‹æ ¼å¼
                hex_key                   # çº¯åå…­è¿›åˆ¶
            ]
        else:
            key_formats = [
                original_key,
                f'"{original_key}"',
                f"x'{original_key}'"
            ]
        
        for i, key_format in enumerate(key_formats):
            try:
                logger.debug(f"   å°è¯•æ–¹å¼{i+1}: PRAGMA key = {key_format}")
                
                conn = sqlite.connect(db_info['path'])
                cursor = conn.cursor()
                
                # è®¾ç½®å¯†é’¥
                cursor.execute(f"PRAGMA key = {key_format}")
                
                # è®¾ç½®å…¼å®¹æ€§
                cursor.execute(f"PRAGMA cipher_compatibility = {db_info['cipher_compatibility']}")
                
                # æµ‹è¯•è¿æ¥
                logger.debug(f"   æµ‹è¯•è¿æ¥: æŸ¥è¯¢ sqlite_master è¡¨...")
                cursor.execute("SELECT count(*) FROM sqlite_master WHERE type='table'")
                table_count = cursor.fetchone()[0]
                
                logger.info(f"âœ… æˆåŠŸè¿æ¥æ•°æ®åº“ {db_name}ï¼ŒåŒ…å« {table_count} ä¸ªè¡¨ (ä½¿ç”¨æ–¹å¼{i+1})")
                return conn
                
            except Exception as e:
                logger.debug(f"   æ–¹å¼{i+1}å¤±è´¥: {str(e)}")
                if conn:
                    conn.close()
                continue
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        logger.warning(f"âŒ æ•°æ®åº“è§£å¯†å¤±è´¥ {db_name}: å°è¯•äº† {len(key_formats)} ç§å¯†é’¥æ ¼å¼éƒ½å¤±è´¥")
        return None
    
    def get_table_names(self, conn: sqlite.Connection) -> List[str]:
        """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰è¡¨å"""
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            return tables
        except Exception as e:
            logger.error(f"è·å–è¡¨åå¤±è´¥: {e}")
            return []
    
    def find_chat_tables(self, tables: List[str]) -> List[str]:
        """
        æŸ¥æ‰¾èŠå¤©è®°å½•è¡¨
        
        Args:
            tables: è¡¨ååˆ—è¡¨
            
        Returns:
            èŠå¤©è¡¨ååˆ—è¡¨
        """
        chat_tables = []
        
        for table in tables:
            name_lower = table.lower()
            
            # åŒ¹é…èŠå¤©è¡¨æ¨¡å¼
            if (name_lower.startswith('chat_') or
                name_lower == 'chat' or
                re.match(r'^chat\d+$', name_lower) or
                name_lower.startswith('chatroom_') or
                name_lower.startswith('message_') or
                ('chat' in name_lower and 'room' in name_lower)):
                chat_tables.append(table)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ŒChat_å¼€å¤´çš„ä¼˜å…ˆ
        chat_tables.sort(key=lambda x: (not x.lower().startswith('chat_'), x.lower()))
        
        logger.info(f"æ‰¾åˆ° {len(chat_tables)} ä¸ªèŠå¤©è¡¨: {chat_tables}")
        return chat_tables
    
    def validate_chat_table(self, conn: sqlite.Connection, table_name: str) -> Tuple[bool, List[str]]:
        """
        éªŒè¯è¡¨æ˜¯å¦æ˜¯æœ‰æ•ˆçš„èŠå¤©è®°å½•è¡¨
        
        Args:
            conn: æ•°æ®åº“è¿æ¥
            table_name: è¡¨å
            
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, å­—æ®µåˆ—è¡¨)
        """
        try:
            cursor = conn.cursor()
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns_info = cursor.fetchall()
            columns = [col[1].lower() for col in columns_info]  # col[1] æ˜¯åˆ—å
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            row_count = cursor.fetchone()[0]
            
            if row_count == 0:
                logger.debug(f"è¡¨ {table_name} æ— æ•°æ®")
                return False, columns
            
            # æ£€æŸ¥å…³é”®å­—æ®µ
            # å¾®ä¿¡çš„å®é™…å­—æ®µç»“æ„: meslocalid, messvrid, msgcreatetime, msgcontent, msgstatus, messagetype ç­‰
            has_msg_id = any(col in columns for col in ['meslocalid', 'messvrid', 'localid'])
            has_time = any('time' in col for col in columns)
            has_content = any(keyword in col for col in columns for keyword in ['content', 'message', 'msg'])
            
            # æ›´å®½æ¾çš„éªŒè¯æ¡ä»¶ï¼šåªè¦æœ‰æ¶ˆæ¯IDæˆ–æ—¶é—´æˆ–å†…å®¹å­—æ®µå°±è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„èŠå¤©è¡¨
            is_valid = has_msg_id or has_time or has_content
            
            if is_valid:
                logger.info(f"âœ“ è¡¨ {table_name} éªŒè¯é€šè¿‡ï¼ŒåŒ…å« {row_count} æ¡è®°å½•")
            else:
                logger.debug(f"âœ— è¡¨ {table_name} éªŒè¯å¤±è´¥ï¼Œç¼ºå°‘å¿…è¦å­—æ®µ")
                logger.debug(f"  æ¶ˆæ¯IDå­—æ®µ: {has_msg_id}, æ—¶é—´å­—æ®µ: {has_time}, å†…å®¹å­—æ®µ: {has_content}")
                logger.debug(f"  æ‰€æœ‰å­—æ®µ: {columns}")
            
            return is_valid, columns
            
        except Exception as e:
            logger.error(f"éªŒè¯è¡¨ {table_name} å¤±è´¥: {e}")
            return False, []
    
    def extract_chat_data(self, conn: sqlite.Connection, table_name: str, columns: List[str], 
                         db_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ä»èŠå¤©è¡¨ä¸­æå–æ•°æ®
        
        Args:
            conn: æ•°æ®åº“è¿æ¥
            table_name: è¡¨å
            columns: å­—æ®µåˆ—è¡¨
            db_info: æ•°æ®åº“ä¿¡æ¯
            
        Returns:
            èŠå¤©è®°å½•åˆ—è¡¨
        """
        messages = []
        
        try:
            cursor = conn.cursor()
            
            # è¯†åˆ«å…³é”®å­—æ®µ
            # å¾®ä¿¡çš„å®é™…å­—æ®µç»“æ„
            sender_col = self._find_column(columns, ['meslocalid', 'messvrid', 'localid'])  # ä½¿ç”¨æ¶ˆæ¯IDä½œä¸ºæ ‡è¯†
            time_col = self._find_column(columns, ['msgcreatetime', 'createtime', 'timestamp', 'time'])
            content_col = self._find_column(columns, ['msgcontent', 'content', 'message', 'msg'])
            msgid_col = self._find_column(columns, ['meslocalid', 'messvrid', 'msgid', 'id', 'localid'])
            type_col = self._find_column(columns, ['messagetype', 'msgtype', 'type'])
            status_col = self._find_column(columns, ['msgstatus', 'status'])
            source_col = self._find_column(columns, ['msgsource', 'source'])
            
            # æ„å»ºæŸ¥è¯¢è¯­å¥
            select_fields = []
            field_mapping = {}
            
            if sender_col:
                select_fields.append(sender_col)
                field_mapping['sender'] = sender_col
            
            if time_col:
                select_fields.append(time_col)
                field_mapping['time'] = time_col
            
            if content_col:
                select_fields.append(content_col)
                field_mapping['content'] = content_col
            
            if msgid_col:
                select_fields.append(msgid_col)
                field_mapping['msgid'] = msgid_col
            
            if type_col:
                select_fields.append(type_col)
                field_mapping['type'] = type_col
            
            # æ·»åŠ å…¶ä»–å¯èƒ½æœ‰ç”¨çš„å­—æ®µ
            for col in columns:
                if col not in select_fields and col not in ['rowid']:
                    select_fields.append(col)
            
            if not select_fields:
                logger.warning(f"è¡¨ {table_name} æ— å¯æå–å­—æ®µ")
                return messages
            
            # åˆ†æ‰¹æŸ¥è¯¢ï¼Œé¿å…å†…å­˜é—®é¢˜
            batch_size = 1000
            offset = 0
            
            while True:
                query = f"SELECT {', '.join(select_fields)} FROM {table_name} LIMIT {batch_size} OFFSET {offset}"
                cursor.execute(query)
                rows = cursor.fetchall()
                
                if not rows:
                    break
                
                for row in rows:
                    message = {
                        'database_path': db_info['path'],
                        'database_type': db_info['type'],
                        'table_name': table_name,
                        'extracted_at': datetime.now().isoformat()
                    }
                    
                    # æ˜ å°„å­—æ®µå€¼
                    for i, field in enumerate(select_fields):
                        value = row[i] if i < len(row) else None
                        
                        # å¤„ç†bytesç±»å‹çš„æ•°æ®
                        if isinstance(value, bytes):
                            try:
                                # å°è¯•è§£ç ä¸ºUTF-8å­—ç¬¦ä¸²
                                value = value.decode('utf-8')
                            except UnicodeDecodeError:
                                # å¦‚æœè§£ç å¤±è´¥ï¼Œè½¬æ¢ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²
                                value = value.hex()
                        
                        # ç‰¹æ®Šå¤„ç†ä¸€äº›å­—æ®µ
                        if field == field_mapping.get('time') and value:
                            # å°è¯•è½¬æ¢æ—¶é—´æˆ³
                            message['timestamp'] = self._convert_timestamp(value)
                            message['timestamp_raw'] = value
                        elif field == field_mapping.get('sender'):
                            message['sender'] = value
                        elif field == field_mapping.get('content'):
                            message['content'] = value
                        elif field == field_mapping.get('msgid'):
                            message['message_id'] = value
                        elif field == field_mapping.get('type'):
                            message['message_type'] = value
                        else:
                            message[field] = value
                    
                    messages.append(message)
                
                offset += batch_size
                
                # è®°å½•è¿›åº¦
                if offset % 10000 == 0:
                    logger.info(f"å·²æå–è¡¨ {table_name} ä¸­ {offset} æ¡è®°å½•...")
            
            logger.info(f"è¡¨ {table_name} æå–å®Œæˆï¼Œæ€»è®¡ {len(messages)} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"æå–è¡¨ {table_name} æ•°æ®å¤±è´¥: {e}")
        
        return messages
    
    def _find_column(self, columns: List[str], candidates: List[str]) -> Optional[str]:
        """åœ¨å­—æ®µåˆ—è¡¨ä¸­æŸ¥æ‰¾åŒ¹é…çš„å­—æ®µ"""
        for candidate in candidates:
            for column in columns:
                if candidate.lower() in column.lower():
                    return column
        return None
    
    def _convert_timestamp(self, timestamp: Any) -> Optional[str]:
        """è½¬æ¢æ—¶é—´æˆ³ä¸ºISOæ ¼å¼"""
        try:
            if isinstance(timestamp, (int, float)):
                # å°è¯•ä¸åŒçš„æ—¶é—´æˆ³æ ¼å¼
                if timestamp > 1e12:  # æ¯«ç§’æ—¶é—´æˆ³
                    dt = datetime.fromtimestamp(timestamp / 1000)
                elif timestamp > 1e9:  # ç§’æ—¶é—´æˆ³
                    dt = datetime.fromtimestamp(timestamp)
                else:
                    return None
                return dt.isoformat()
            elif isinstance(timestamp, str):
                # å°è¯•è§£æå­—ç¬¦ä¸²æ—¶é—´
                try:
                    dt = datetime.fromisoformat(timestamp)
                    return dt.isoformat()
                except:
                    return timestamp
        except Exception:
            pass
        return None
    
    def extract_all_chats(self) -> None:
        """æå–æ‰€æœ‰æ•°æ®åº“ä¸­çš„èŠå¤©è®°å½•"""
        logger.info("\nğŸš€ å¼€å§‹æå–æ‰€æœ‰èŠå¤©è®°å½•...")
        logger.info(f"ğŸ“‹ å¾…å¤„ç†æ•°æ®åº“: {len(self.databases)} ä¸ª")
        
        total_messages = 0
        processed_dbs = 0
        
        # ä¼˜å…ˆå¤„ç†Messageç±»å‹çš„æ•°æ®åº“
        message_dbs = [db for db in self.databases if db['type'] == 'Message']
        other_dbs = [db for db in self.databases if db['type'] != 'Message']
        
        for db_info in message_dbs + other_dbs:
            logger.info(f"\nğŸ“Š å¤„ç†æ•°æ®åº“: {Path(db_info['path']).name} (ç±»å‹: {db_info['type']})")
            
            conn = self.connect_database(db_info)
            if not conn:
                continue
            
            try:
                # è·å–æ‰€æœ‰è¡¨
                tables = self.get_table_names(conn)
                
                # æŸ¥æ‰¾èŠå¤©è¡¨
                chat_tables = self.find_chat_tables(tables)
                
                if not chat_tables:
                    logger.info(f"ğŸ“ æ•°æ®åº“ä¸­æ— èŠå¤©è¡¨")
                    continue
                
                # å¤„ç†æ¯ä¸ªèŠå¤©è¡¨
                for table_name in chat_tables:
                    is_valid, columns = self.validate_chat_table(conn, table_name)
                    
                    if not is_valid:
                        continue
                    
                    # æå–æ•°æ®
                    messages = self.extract_chat_data(conn, table_name, columns, db_info)
                    self.chat_data.extend(messages)
                    total_messages += len(messages)
                
                processed_dbs += 1
                
            finally:
                conn.close()
        
        logger.info(f"\nğŸ‰ æå–å®Œæˆ!")
        logger.info(f"ğŸ“Š å¤„ç†äº† {processed_dbs} ä¸ªæ•°æ®åº“")
        logger.info(f"ğŸ’¬ æ€»è®¡æå– {total_messages} æ¡èŠå¤©è®°å½•")
    
    def save_to_json(self, output_path: str) -> None:
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        try:
            output_file = Path(output_path)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            # å‡†å¤‡è¾“å‡ºæ•°æ®
            output_data = {
                'metadata': {
                    'extracted_at': datetime.now().isoformat(),
                    'total_messages': len(self.chat_data),
                    'total_databases': len(self.databases),
                    'source_keys_file': str(self.keys_file_path)
                },
                'messages': self.chat_data
            }
            
            # ä¿å­˜JSONæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {output_file.stat().st_size / (1024*1024):.2f} MB")
            
        except Exception as e:
            logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def run(self, output_path: str) -> None:
        """è¿è¡Œå®Œæ•´çš„æå–æµç¨‹"""
        try:
            # åŠ è½½é…ç½®
            self.load_keys()
            
            if not self.databases:
                logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åº“")
                return
            
            # æå–èŠå¤©è®°å½•
            self.extract_all_chats()
            
            if not self.chat_data:
                logger.warning("æœªæå–åˆ°ä»»ä½•èŠå¤©è®°å½•")
                return
            
            # ä¿å­˜ç»“æœ
            self.save_to_json(output_path)
            
        except Exception as e:
            logger.error(f"æå–è¿‡ç¨‹å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='WeChatèŠå¤©è®°å½•æå–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python wechat_chat_extractor.py .keys
  python wechat_chat_extractor.py /path/to/.keys -o output.json
  python wechat_chat_extractor.py .keys -o /path/to/output.json
  python wechat_chat_extractor.py .keys --show-tables
  python wechat_chat_extractor.py .keys --show-tables -v
  python wechat_chat_extractor.py .keys --test-info
  python wechat_chat_extractor.py .keys --csv-tables tables.csv

æ³¨æ„:
  - éœ€è¦å®‰è£…ä¾èµ–: pip install pysqlcipher3
  - .keysæ–‡ä»¶åº”åŒ…å«æ•°æ®åº“è·¯å¾„å’Œè§£å¯†å¯†é’¥
  - è¾“å‡ºçš„JSONæ–‡ä»¶å¯èƒ½å¾ˆå¤§ï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
  - ä½¿ç”¨ --show-tables æŸ¥çœ‹æ•°æ®åº“å’Œè¡¨ä¿¡æ¯è€Œä¸æå–æ•°æ®
  - ä½¿ç”¨ --test-info æŸ¥çœ‹æ•°æ®åº“è¿æ¥ä¿¡æ¯
  - ä½¿ç”¨ --csv-tables å¯¼å‡ºèŠå¤©è¡¨ä¿¡æ¯åˆ°CSVæ–‡ä»¶
        """
    )
    
    parser.add_argument('keys_file', help='.keysæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', default='wechat_chat_export.json', 
                       help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ (é»˜è®¤: wechat_chat_export.json)')
    parser.add_argument('-v', '--verbose', action='store_true', 
                       help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    parser.add_argument('--test-info', action='store_true',
                       help='ä»…æ˜¾ç¤ºæ•°æ®åº“è·¯å¾„å’Œå¯†é’¥ä¿¡æ¯ï¼Œé€‚åˆå¤åˆ¶åˆ°å…¶ä»–åº”ç”¨æµ‹è¯•')
    parser.add_argument('--show-tables', action='store_true',
                       help='ä»…æ˜¾ç¤ºæ¯ä¸ªæ•°æ®åº“å’Œå…¶ä¸­çš„è¡¨ä¿¡æ¯ï¼Œä¸è¯»å–è¡¨æ ¼å†…å®¹')
    parser.add_argument('--csv-tables', 
                       help='å¯¼å‡ºèŠå¤©è¡¨ä¿¡æ¯åˆ°CSVæ–‡ä»¶ï¼ŒåŒ…å«æ•°æ®åº“åã€åœ°å€ã€è¡¨åç­‰ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # æµ‹è¯•ä¿¡æ¯æ¨¡å¼
    if args.test_info:
        # ç¦ç”¨æ—¥å¿—è¾“å‡º
        logging.getLogger().setLevel(logging.ERROR)
        
        extractor = WeChatChatExtractor(args.keys_file)
        extractor.load_keys()
        
        print("# WeChatæ•°æ®åº“è¿æ¥ä¿¡æ¯")
        print("# æ ¼å¼: è·¯å¾„ | å¯†é’¥ | cipher_compatibility")
        print("# " + "="*80)
        
        for db in extractor.databases:
            print(f"è·¯å¾„: {db['path']}")
            print(f"å¯†é’¥: {db['key']}")
            print(f"cipher_compatibility: {db['cipher_compatibility']}")
            print("-" * 80)
        
        return
    
    # æ˜¾ç¤ºè¡¨ä¿¡æ¯æ¨¡å¼
    if args.show_tables:
        # è®¾ç½®ç®€æ´æ—¥å¿—
        logging.getLogger().setLevel(logging.INFO)
        
        extractor = WeChatChatExtractor(args.keys_file)
        extractor.load_keys()
        
        print("# WeChatæ•°æ®åº“è¡¨ä¿¡æ¯")
        print("# " + "="*80)
        
        for db_info in extractor.databases:
            print(f"\nğŸ“ æ•°æ®åº“: {Path(db_info['path']).name}")
            print(f"   ç±»å‹: {db_info['type']}")
            print(f"   è·¯å¾„: {db_info['path']}")
            print(f"   å¤§å°: {os.path.getsize(db_info['path']):,} bytes")
            
            # å°è¯•è¿æ¥æ•°æ®åº“
            conn = extractor.connect_database(db_info)
            if conn:
                try:
                    # è·å–æ‰€æœ‰è¡¨
                    tables = extractor.get_table_names(conn)
                    print(f"   è¡¨æ•°é‡: {len(tables)}")
                    
                    # æŸ¥æ‰¾èŠå¤©è¡¨
                    chat_tables = extractor.find_chat_tables(tables)
                    print(f"   èŠå¤©è¡¨æ•°é‡: {len(chat_tables)}")
                    
                    if chat_tables:
                        print("   èŠå¤©è¡¨:")
                        for table in chat_tables:
                            print(f"     - {table}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰è¡¨ï¼ˆå¯é€‰ï¼‰
                    if args.verbose:
                        print(f"   æ‰€æœ‰è¡¨ ({len(tables)}):")
                        for table in tables:
                            print(f"     - {table}")
                    
                finally:
                    conn.close()
            else:
                print("   âŒ è¿æ¥å¤±è´¥")
            
            print("   " + "-"*60)
        
        return
    
    # CSVå¯¼å‡ºèŠå¤©è¡¨ä¿¡æ¯æ¨¡å¼
    if args.csv_tables:
        # è®¾ç½®ç®€æ´æ—¥å¿—
        logging.getLogger().setLevel(logging.INFO)
        
        extractor = WeChatChatExtractor(args.keys_file)
        extractor.load_keys()
        
        print(f"ğŸ“Š å¯¼å‡ºèŠå¤©è¡¨ä¿¡æ¯åˆ°CSVæ–‡ä»¶: {args.csv_tables}")
        
        # æ”¶é›†æ‰€æœ‰èŠå¤©è¡¨ä¿¡æ¯
        table_info = []
        
        for db_info in extractor.databases:
            print(f"ğŸ” å¤„ç†æ•°æ®åº“: {Path(db_info['path']).name}")
            
            # å°è¯•è¿æ¥æ•°æ®åº“
            conn = extractor.connect_database(db_info)
            if conn:
                try:
                    # è·å–æ‰€æœ‰è¡¨
                    tables = extractor.get_table_names(conn)
                    
                    # æŸ¥æ‰¾èŠå¤©è¡¨
                    chat_tables = extractor.find_chat_tables(tables)
                    
                    for table_name in chat_tables:
                        # éªŒè¯è¡¨å¹¶è·å–å­—æ®µä¿¡æ¯
                        is_valid, columns = extractor.validate_chat_table(conn, table_name)
                        
                        if is_valid:
                            # è·å–è¡¨çš„è®°å½•æ•°
                            try:
                                cursor = conn.cursor()
                                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                                row_count = cursor.fetchone()[0]
                            except:
                                row_count = 0
                            
                            table_info.append({
                                'database_name': Path(db_info['path']).name,
                                'database_type': db_info['type'],
                                'database_path': db_info['path'],
                                'database_size': os.path.getsize(db_info['path']),
                                'table_name': table_name,
                                'table_type': 'chat',
                                'row_count': row_count,
                                'column_count': len(columns),
                                'columns': ', '.join(columns),
                                'key': db_info['key'],
                                'cipher_compatibility': db_info['cipher_compatibility'],
                                'extracted_at': datetime.now().isoformat()
                            })
                    
                finally:
                    conn.close()
            else:
                print(f"âŒ æ— æ³•è¿æ¥æ•°æ®åº“: {Path(db_info['path']).name}")
        
        # å¯¼å‡ºåˆ°CSVæ–‡ä»¶
        if table_info:
            csv_path = Path(args.csv_tables)
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = [
                    'database_name', 'database_type', 'database_path', 'database_size',
                    'table_name', 'table_type', 'row_count', 'column_count', 'columns',
                    'key', 'cipher_compatibility', 'extracted_at'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(table_info)
            
            print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {csv_path}")
            print(f"ğŸ“Š å¯¼å‡ºäº† {len(table_info)} ä¸ªèŠå¤©è¡¨çš„ä¿¡æ¯")
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {csv_path.stat().st_size / 1024:.2f} KB")
            
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„èŠå¤©è¡¨")
        
        return
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.keys_file):
        print(f"é”™è¯¯: keysæ–‡ä»¶ä¸å­˜åœ¨: {args.keys_file}")
        sys.exit(1)
    
    logger.info("ğŸš€ WeChatèŠå¤©è®°å½•æå–å·¥å…·")
    logger.info(f"ğŸ“ Keysæ–‡ä»¶: {args.keys_file}")
    logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {args.output}")
    
    try:
        extractor = WeChatChatExtractor(args.keys_file)
        extractor.run(args.output)
        
        logger.info("âœ… æå–å®Œæˆ!")
        
    except KeyboardInterrupt:
        logger.info("âŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ æå–å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()